{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "ymeHhUgGL1NX"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torchvision import transforms,datasets,models"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.random.seed(42)\n",
        "torch.manual_seed(42)"
      ],
      "metadata": {
        "id": "6F7DEyRHL8RD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6f807d40-258b-4262-fe06-dbd2050e7a5c"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7e63837a52b0>"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.0,), (1.0,))])\n",
        "dataset = datasets.MNIST(root = './data', train=True, transform = transform, download=True)\n",
        "train_set, val_set = torch.utils.data.random_split(dataset, [50000, 10000])\n",
        "test_set = datasets.MNIST(root = './data', train=False, transform = transform, download=True)\n",
        "train_loader = torch.utils.data.DataLoader(train_set,batch_size=1,shuffle=True)\n",
        "val_loader = torch.utils.data.DataLoader(val_set,batch_size=1,shuffle=True)\n",
        "test_loader = torch.utils.data.DataLoader(test_set,batch_size=1,shuffle=True)"
      ],
      "metadata": {
        "id": "yqeIFlaML-EZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "87d8f276-fd58-467b-8d87-84a6d31d86cd"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ./data/MNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9912422/9912422 [00:00<00:00, 68825184.94it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/train-images-idx3-ubyte.gz to ./data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to ./data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 28881/28881 [00:00<00:00, 81299123.37it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/train-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "100%|██████████| 1648877/1648877 [00:00<00:00, 21383094.22it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4542/4542 [00:00<00:00, 13685724.69it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Training data:\",len(train_loader),\"Validation data:\",len(val_loader),\"Test data: \",len(test_loader))"
      ],
      "metadata": {
        "id": "Z0pTnLlpL_PP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5e78355c-ddc7-4967-81d7-52d105b04698"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training data: 50000 Validation data: 10000 Test data:  10000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "use_cuda=True\n",
        "device = torch.device(\"cuda\" if (use_cuda and torch.cuda.is_available()) else \"cpu\")"
      ],
      "metadata": {
        "id": "HyqQ7TgJMBLf"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ATTACK\n",
        "# Attack on VGG16\n"
      ],
      "metadata": {
        "id": "62FjepjiMCVg"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class VGG16_for_MNIST(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(VGG16_for_MNIST, self).__init__()\n",
        "        original_vgg16 = models.vgg16(pretrained=True)\n",
        "        self.features = original_vgg16.features\n",
        "\n",
        "        # Adapt the classifier part of VGG16 for MNIST\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Linear(512 * 7 * 7, 4096),  # Adjust the first layer to match the feature map size\n",
        "            nn.ReLU(True),\n",
        "            nn.Dropout(),\n",
        "            nn.Linear(4096, 4096),\n",
        "            nn.ReLU(True),\n",
        "            nn.Dropout(),\n",
        "            nn.Linear(4096, 10)  # Output layer for 10 classes\n",
        "        )\n",
        "\n",
        "        # Override the forward method\n",
        "    def forward(self, x):\n",
        "        # VGG16 expects 3 channel input, so replicate the grayscale MNIST image across 3 channels\n",
        "        x = x.repeat(1, 3, 1, 1)  # Input is [N, 1, 28, 28] but needs to be [N, 3, 28, 28]\n",
        "        x = F.interpolate(x, size=(224, 224))  # Resize images from 28x28 to 224x224\n",
        "        x = self.features(x)  # Apply VGG16 features\n",
        "        x = torch.flatten(x, 1)\n",
        "        x = self.classifier(x)  # Classify with the modified classifier\n",
        "        return F.log_softmax(x, dim=1)"
      ],
      "metadata": {
        "id": "Ir9Um8MuYL_e"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = VGG16_for_MNIST().to(device)"
      ],
      "metadata": {
        "id": "k41hyIDLY2Hv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "52dde8a1-f20f-4d77-8a6d-7d978027557a"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG16_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/vgg16-397923af.pth\" to /root/.cache/torch/hub/checkpoints/vgg16-397923af.pth\n",
            "100%|██████████| 528M/528M [00:06<00:00, 86.7MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = optim.Adam(model.parameters(),lr=0.0001, betas=(0.9, 0.999))\n",
        "criterion = nn.NLLLoss()\n",
        "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=3)"
      ],
      "metadata": {
        "id": "vHtGwASjY6FA"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def fit(model,device,train_loader,val_loader,epochs):\n",
        "  data_loader = {'train':train_loader,'val':val_loader}\n",
        "  print(\"Fitting the model...\")\n",
        "  train_loss,val_loss=[],[]\n",
        "  for epoch in range(epochs):\n",
        "    loss_per_epoch,val_loss_per_epoch=0,0\n",
        "    for phase in ('train','val'):\n",
        "      for i,data in enumerate(data_loader[phase]):\n",
        "        input,label  = data[0].to(device),data[1].to(device)\n",
        "        output = model(input)\n",
        "        #calculating loss on the output\n",
        "        loss = criterion(output,label)\n",
        "        if phase == 'train':\n",
        "          optimizer.zero_grad()\n",
        "          #grad calc w.r.t Loss func\n",
        "          loss.backward()\n",
        "          #update weights\n",
        "          optimizer.step()\n",
        "          loss_per_epoch+=loss.item()\n",
        "        else:\n",
        "          val_loss_per_epoch+=loss.item()\n",
        "    scheduler.step(val_loss_per_epoch/len(val_loader))\n",
        "    print(\"Epoch: {} Loss: {} Val_Loss: {}\".format(epoch+1,loss_per_epoch/len(train_loader),val_loss_per_epoch/len(val_loader)))\n",
        "    train_loss.append(loss_per_epoch/len(train_loader))\n",
        "    val_loss.append(val_loss_per_epoch/len(val_loader))\n",
        "  return train_loss,val_loss"
      ],
      "metadata": {
        "id": "ISgXXVJcZUCh"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss,val_loss=fit(model,device,train_loader,val_loader,5) # 10 is better but too long time"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JitC66BSZVrh",
        "outputId": "a31c73d6-ec98-42b7-f32e-334cd540ab64"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting the model...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fig = plt.figure(figsize=(5,5))\n",
        "plt.plot(np.arange(1,6), loss, \"*-\",label=\"Loss\")\n",
        "plt.plot(np.arange(1,6), val_loss,\"o-\",label=\"Val Loss\")\n",
        "plt.xlabel(\"Num of epochs\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "yjWJERpImsma"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def fgsm_attack(input,epsilon,data_grad):\n",
        "  pert_out = input + epsilon*data_grad.sign()\n",
        "  pert_out = torch.clamp(pert_out, 0, 1)\n",
        "  return pert_out\n",
        "\n",
        "def ifgsm_attack(input,epsilon,data_grad):\n",
        "  iter = 10\n",
        "  alpha = epsilon/iter\n",
        "  pert_out = input\n",
        "  for i in range(iter-1):\n",
        "    pert_out = pert_out + alpha*data_grad.sign()\n",
        "    pert_out = torch.clamp(pert_out, 0, 1)\n",
        "    if torch.norm((pert_out-input),p=float('inf')) > epsilon:\n",
        "      break\n",
        "  return pert_out\n",
        "\n",
        "def mifgsm_attack(input,epsilon,data_grad):\n",
        "  iter=10\n",
        "  decay_factor=1.0\n",
        "  pert_out = input\n",
        "  alpha = epsilon/iter\n",
        "  g=0\n",
        "  for i in range(iter-1):\n",
        "    g = decay_factor*g + data_grad/torch.norm(data_grad,p=1)\n",
        "    pert_out = pert_out + alpha*torch.sign(g)\n",
        "    pert_out = torch.clamp(pert_out, 0, 1)\n",
        "    if torch.norm((pert_out-input),p=float('inf')) > epsilon:\n",
        "      break\n",
        "  return pert_out"
      ],
      "metadata": {
        "id": "85EtXtDpsTSA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def test(model,device,test_loader,epsilon,attack):\n",
        "  correct = 0\n",
        "  adv_examples = []\n",
        "  for data, target in test_loader:\n",
        "      data, target = data.to(device), target.to(device)\n",
        "      data.requires_grad = True\n",
        "      output = model(data)\n",
        "      init_pred = output.max(1, keepdim=True)[1]\n",
        "      if init_pred.item() != target.item():\n",
        "          continue\n",
        "      loss = F.nll_loss(output, target)\n",
        "      model.zero_grad()\n",
        "      loss.backward()\n",
        "      data_grad = data.grad.data\n",
        "\n",
        "      if attack == \"fgsm\":\n",
        "        perturbed_data = fgsm_attack(data,epsilon,data_grad)\n",
        "      elif attack == \"ifgsm\":\n",
        "        perturbed_data = ifgsm_attack(data,epsilon,data_grad)\n",
        "      elif attack == \"mifgsm\":\n",
        "        perturbed_data = mifgsm_attack(data,epsilon,data_grad)\n",
        "\n",
        "      output = model(perturbed_data)\n",
        "      final_pred = output.max(1, keepdim=True)[1]\n",
        "      if final_pred.item() == target.item():\n",
        "          correct += 1\n",
        "          if (epsilon == 0) and (len(adv_examples) < 5):\n",
        "              adv_ex = perturbed_data.squeeze().detach().cpu().numpy()\n",
        "              adv_examples.append( (init_pred.item(), final_pred.item(), adv_ex) )\n",
        "      else:\n",
        "          if len(adv_examples) < 5:\n",
        "              adv_ex = perturbed_data.squeeze().detach().cpu().numpy()\n",
        "              adv_examples.append( (init_pred.item(), final_pred.item(), adv_ex) )\n",
        "\n",
        "  final_acc = correct/float(len(test_loader))\n",
        "  print(\"Epsilon: {}\\tTest Accuracy = {} / {} = {}\".format(epsilon, correct, len(test_loader), final_acc))\n",
        "\n",
        "  return final_acc, adv_examples\n"
      ],
      "metadata": {
        "id": "s4o2-3SMsVlE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#epsilons = [0,0.007,0.01,0.02,0.03,0.05,0.1,0.2,0.3]\n",
        "epsilons = [0,0.05,0.1,0.2,0.3]\n",
        "for attack in (\"fgsm\",\"ifgsm\",\"mifgsm\"):\n",
        "  accuracies = []\n",
        "  examples = []\n",
        "  for eps in epsilons:\n",
        "      acc, ex = test(model, device,test_loader,eps,attack)\n",
        "      accuracies.append(acc)\n",
        "      examples.append(ex)\n",
        "  plt.figure(figsize=(5,5))\n",
        "  plt.plot(epsilons, accuracies, \"*-\")\n",
        "  plt.title(attack)\n",
        "  plt.xlabel(\"Epsilon\")\n",
        "  plt.ylabel(\"Accuracy\")\n",
        "  plt.show()\n",
        "\n",
        "  cnt = 0\n",
        "  plt.figure(figsize=(8,10))\n",
        "  for i in range(len(epsilons)):\n",
        "      for j in range(len(examples[i])):\n",
        "          cnt += 1\n",
        "          plt.subplot(len(epsilons),len(examples[0]),cnt)\n",
        "          plt.xticks([], [])\n",
        "          plt.yticks([], [])\n",
        "          if j == 0:\n",
        "              plt.ylabel(\"Eps: {}\".format(epsilons[i]), fontsize=14)\n",
        "          orig,adv,ex = examples[i][j]\n",
        "          plt.title(\"{} -> {}\".format(orig, adv))\n",
        "          plt.imshow(ex, cmap=\"gray\")\n",
        "  plt.tight_layout()\n",
        "  plt.show()"
      ],
      "metadata": {
        "id": "f47IYV1WsWBI"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}