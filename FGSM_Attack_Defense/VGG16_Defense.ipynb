{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "xrWfxGmNnwmB"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torchvision import transforms,datasets,models"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.random.seed(42)\n",
        "torch.manual_seed(42)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ET_WWl8Zocp6",
        "outputId": "173d8f19-9f22-4ff4-8fce-8b352a511a7c"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7a07dc73d630>"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.0,), (1.0,))])\n",
        "dataset = datasets.MNIST(root = './data', train=True, transform = transform, download=True)\n",
        "train_set, val_set = torch.utils.data.random_split(dataset, [50000, 10000])\n",
        "test_set = datasets.MNIST(root = './data', train=False, transform = transform, download=True)\n",
        "train_loader = torch.utils.data.DataLoader(train_set,batch_size=1,shuffle=True)\n",
        "val_loader = torch.utils.data.DataLoader(val_set,batch_size=1,shuffle=True)\n",
        "test_loader = torch.utils.data.DataLoader(test_set,batch_size=1,shuffle=True)"
      ],
      "metadata": {
        "id": "WocUkIGAoj0K"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Training data:\",len(train_loader),\"Validation data:\",len(val_loader),\"Test data: \",len(test_loader))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zlhBqzNFokzy",
        "outputId": "80117893-3fae-44bc-b239-640db1e8be6e"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training data: 50000 Validation data: 10000 Test data:  10000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "use_cuda=True\n",
        "device = torch.device(\"cuda\" if (use_cuda and torch.cuda.is_available()) else \"cpu\")"
      ],
      "metadata": {
        "id": "okaojGBnomo2"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Defense\n",
        "# VGG16 for NetF\n",
        "\n",
        "class NetF(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(NetF, self).__init__()\n",
        "        original_vgg16 = models.vgg16(pretrained=True)\n",
        "        self.features = original_vgg16.features\n",
        "\n",
        "        # Adapt the classifier part of VGG16 for MNIST\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Linear(512 * 7 * 7, 4096),  # Adjust the first layer to match the feature map size\n",
        "            nn.ReLU(True),\n",
        "            nn.Dropout(),\n",
        "            nn.Linear(4096, 4096),\n",
        "            nn.ReLU(True),\n",
        "            nn.Dropout(),\n",
        "            nn.Linear(4096, 10)  # Output layer for 10 classes\n",
        "        )\n",
        "\n",
        "        # Override the forward method\n",
        "    def forward(self, x):\n",
        "        # VGG16 expects 3 channel input, so replicate the grayscale MNIST image across 3 channels\n",
        "        x = x.repeat(1, 3, 1, 1)  # Input is [N, 1, 28, 28] but needs to be [N, 3, 28, 28]\n",
        "        x = F.interpolate(x, size=(224, 224))  # Resize images from 28x28 to 224x224\n",
        "        x = self.features(x)  # Apply VGG16 features\n",
        "        x = torch.flatten(x, 1)\n",
        "        x = self.classifier(x)  # Classify with the modified classifier\n",
        "        return x\n",
        "\n",
        "\n",
        "class NetF1(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(NetF1, self).__init__()\n",
        "        original_vgg16 = models.vgg16(pretrained=True)\n",
        "        self.features = original_vgg16.features\n",
        "\n",
        "        # Adapt the classifier part of VGG16 for MNIST\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Linear(256 * 7 * 7, 2048),  # Adjust the first layer to match the feature map size\n",
        "            nn.ReLU(True),\n",
        "            nn.Dropout(),\n",
        "            nn.Linear(2048, 2048),\n",
        "            nn.ReLU(True),\n",
        "            nn.Dropout(),\n",
        "            nn.Linear(2048, 10)  # Output layer for 10 classes\n",
        "        )\n",
        "\n",
        "        # Override the forward method\n",
        "    def forward(self, x):\n",
        "        # VGG16 expects 3 channel input, so replicate the grayscale MNIST image across 3 channels\n",
        "        x = x.repeat(1, 3, 1, 1)  # Input is [N, 1, 28, 28] but needs to be [N, 3, 28, 28]\n",
        "        x = F.interpolate(x, size=(224, 224))  # Resize images from 28x28 to 224x224\n",
        "        x = self.features(x)  # Apply VGG16 features\n",
        "        x = torch.flatten(x, 1)\n",
        "        x = self.classifier(x)  # Classify with the modified classifier\n",
        "        return x"
      ],
      "metadata": {
        "id": "MH0ilIWFonyR"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def fgsm_attack(input,epsilon,data_grad):\n",
        "  pert_out = input + epsilon*data_grad.sign()\n",
        "  pert_out = torch.clamp(pert_out, 0, 1)\n",
        "  return pert_out\n",
        "\n",
        "def ifgsm_attack(input,epsilon,data_grad):\n",
        "  iter = 10\n",
        "  alpha = epsilon/iter\n",
        "  pert_out = input\n",
        "  for i in range(iter-1):\n",
        "    pert_out = pert_out + alpha*data_grad.sign()\n",
        "    pert_out = torch.clamp(pert_out, 0, 1)\n",
        "    if torch.norm((pert_out-input),p=float('inf')) > epsilon:\n",
        "      break\n",
        "  return pert_out\n",
        "\n",
        "def mifgsm_attack(input,epsilon,data_grad):\n",
        "  iter=10\n",
        "  decay_factor=1.0\n",
        "  alpha = epsilon/iter\n",
        "  pert_out = input\n",
        "  g=0\n",
        "  for i in range(iter-1):\n",
        "    g = decay_factor*g + data_grad/torch.norm(data_grad,p=1)\n",
        "    pert_out = pert_out + alpha*torch.sign(g)\n",
        "    pert_out = torch.clamp(pert_out, 0, 1)\n",
        "    if torch.norm((pert_out-input),p=float('inf')) > epsilon:\n",
        "      break\n",
        "  return pert_out"
      ],
      "metadata": {
        "id": "GZClsMyuqWKe"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def fit(model,device,optimizer,scheduler,criterion,train_loader,val_loader,Temp,epochs):\n",
        "  data_loader = {'train':train_loader,'val':val_loader}\n",
        "  print(\"Fitting the model...\")\n",
        "  train_loss,val_loss=[],[]\n",
        "  for epoch in range(epochs):\n",
        "    loss_per_epoch,val_loss_per_epoch=0,0\n",
        "    for phase in ('train','val'):\n",
        "      for i,data in enumerate(data_loader[phase]):\n",
        "        input,label  = data[0].to(device),data[1].to(device)\n",
        "        output = model(input)\n",
        "        output = F.log_softmax(output/Temp,dim=1)\n",
        "        #calculating loss on the output\n",
        "        loss = criterion(output,label)\n",
        "        if phase == 'train':\n",
        "          optimizer.zero_grad()\n",
        "          #grad calc w.r.t Loss func\n",
        "          loss.backward()\n",
        "          #update weights\n",
        "          optimizer.step()\n",
        "          loss_per_epoch+=loss.item()\n",
        "        else:\n",
        "          val_loss_per_epoch+=loss.item()\n",
        "    scheduler.step(val_loss_per_epoch/len(val_loader))\n",
        "    print(\"Epoch: {} Loss: {} Val_Loss: {}\".format(epoch+1,loss_per_epoch/len(train_loader),val_loss_per_epoch/len(val_loader)))\n",
        "    train_loss.append(loss_per_epoch/len(train_loader))\n",
        "    val_loss.append(val_loss_per_epoch/len(val_loader))\n",
        "  return train_loss,val_loss\n",
        "\n",
        "def test(model,device,test_loader,epsilon,Temp,attack):\n",
        "  correct=0\n",
        "  adv_examples = []\n",
        "  for data, target in test_loader:\n",
        "    data, target = data.to(device), target.to(device)\n",
        "    data.requires_grad = True\n",
        "    output = model(data)\n",
        "    output = F.log_softmax(output/Temp,dim=1)\n",
        "    init_pred = output.max(1, keepdim=True)[1]\n",
        "    if init_pred.item() != target.item():\n",
        "        continue\n",
        "    loss = F.nll_loss(output, target)\n",
        "    model.zero_grad()\n",
        "    loss.backward()\n",
        "    data_grad = data.grad.data\n",
        "\n",
        "    if attack == \"fgsm\":\n",
        "      perturbed_data = fgsm_attack(data,epsilon,data_grad)\n",
        "    elif attack == \"ifgsm\":\n",
        "      perturbed_data = ifgsm_attack(data,epsilon,data_grad)\n",
        "    elif attack == \"mifgsm\":\n",
        "      perturbed_data = mifgsm_attack(data,epsilon,data_grad)\n",
        "\n",
        "    output = model(perturbed_data)\n",
        "    final_pred = output.max(1, keepdim=True)[1]\n",
        "    if final_pred.item() == target.item():\n",
        "        correct += 1\n",
        "        if (epsilon == 0) and (len(adv_examples) < 5):\n",
        "            adv_ex = perturbed_data.squeeze().detach().cpu().numpy()\n",
        "            adv_examples.append( (init_pred.item(), final_pred.item(), adv_ex) )\n",
        "    else:\n",
        "        if len(adv_examples) < 5:\n",
        "            adv_ex = perturbed_data.squeeze().detach().cpu().numpy()\n",
        "            adv_examples.append( (init_pred.item(), final_pred.item(), adv_ex) )\n",
        "\n",
        "  final_acc = correct/float(len(test_loader))\n",
        "  print(\"Epsilon: {}\\tTest Accuracy = {} / {} = {}\".format(epsilon, correct, len(test_loader), final_acc))\n",
        "\n",
        "  return final_acc,adv_examples"
      ],
      "metadata": {
        "id": "OXycr-6VqW1B"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def defense(device,train_loader,val_loader,test_loader,epochs,Temp,epsilons):\n",
        "\n",
        "  modelF = NetF().to(device)\n",
        "  optimizerF = optim.Adam(modelF.parameters(),lr=0.0001, betas=(0.9, 0.999))\n",
        "  schedulerF = optim.lr_scheduler.ReduceLROnPlateau(optimizerF, mode='min', factor=0.1, patience=3)\n",
        "\n",
        "  modelF1 = NetF1().to(device)\n",
        "  optimizerF1 = optim.Adam(modelF1.parameters(),lr=0.0001, betas=(0.9, 0.999))\n",
        "  schedulerF1 = optim.lr_scheduler.ReduceLROnPlateau(optimizerF1, mode='min', factor=0.1, patience=3)\n",
        "\n",
        "  criterion = nn.NLLLoss()\n",
        "\n",
        "  lossF,val_lossF=fit(modelF,device,optimizerF,schedulerF,criterion,train_loader,val_loader,Temp,epochs)\n",
        "  fig = plt.figure(figsize=(5,5))\n",
        "  plt.plot(np.arange(1,epochs+1), lossF, \"*-\",label=\"Loss\")\n",
        "  plt.plot(np.arange(1,epochs+1), val_lossF,\"o-\",label=\"Val Loss\")\n",
        "  plt.title(\"Network F\")\n",
        "  plt.xlabel(\"Num of epochs\")\n",
        "  plt.legend()\n",
        "  plt.show()\n",
        "\n",
        "  #converting target labels to soft labels\n",
        "  for data in train_loader:\n",
        "    input, label  = data[0].to(device),data[1].to(device)\n",
        "    softlabel  = F.log_softmax(modelF(input),dim=1)\n",
        "    data[1] = softlabel\n",
        "\n",
        "  lossF1,val_lossF1=fit(modelF1,device,optimizerF1,schedulerF1,criterion,train_loader,val_loader,Temp,epochs)\n",
        "  fig = plt.figure(figsize=(5,5))\n",
        "  plt.plot(np.arange(1,epochs+1), lossF1, \"*-\",label=\"Loss\")\n",
        "  plt.plot(np.arange(1,epochs+1), val_lossF1,\"o-\",label=\"Val Loss\")\n",
        "  plt.title(\"Network F'\")\n",
        "  plt.xlabel(\"Num of epochs\")\n",
        "  plt.legend()\n",
        "  plt.show()\n",
        "\n",
        "  model = NetF1().to(device)\n",
        "  model.load_state_dict(modelF1.state_dict())\n",
        "  for attack in (\"fgsm\",\"ifgsm\",\"mifgsm\"):\n",
        "    accuracies = []\n",
        "    examples = []\n",
        "    for eps in epsilons:\n",
        "        acc, ex = test(model,device,test_loader,eps,1,\"fgsm\")\n",
        "        accuracies.append(acc)\n",
        "        examples.append(ex)\n",
        "\n",
        "    plt.figure(figsize=(5,5))\n",
        "    plt.plot(epsilons, accuracies, \"*-\")\n",
        "    plt.title(attack)\n",
        "    plt.xlabel(\"Epsilon\")\n",
        "    plt.ylabel(\"Accuracy\")\n",
        "    plt.show()\n",
        "\n",
        "    cnt = 0\n",
        "    plt.figure(figsize=(8,10))\n",
        "    for i in range(len(epsilons)):\n",
        "        for j in range(len(examples[i])):\n",
        "            cnt += 1\n",
        "            plt.subplot(len(epsilons),len(examples[0]),cnt)\n",
        "            plt.xticks([], [])\n",
        "            plt.yticks([], [])\n",
        "            if j == 0:\n",
        "                plt.ylabel(\"Eps: {}\".format(epsilons[i]), fontsize=14)\n",
        "            orig,adv,ex = examples[i][j]\n",
        "            plt.title(\"{} -> {}\".format(orig, adv))\n",
        "            plt.imshow(ex, cmap=\"gray\")\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "UWnBNIOTqZqx"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Temp=100\n",
        "epochs=5\n",
        "epsilons=[0,0.05,0.1,0.2,0.3]\n",
        "defense(device,train_loader,val_loader,test_loader,epochs,Temp,epsilons)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "douWNTIbqaeV",
        "outputId": "a4e64ed5-bcd6-4e40-9765-3eb67c90d886"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG16_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/vgg16-397923af.pth\" to /root/.cache/torch/hub/checkpoints/vgg16-397923af.pth\n",
            "100%|██████████| 528M/528M [00:06<00:00, 83.4MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting the model...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "C3EDc0FirPH2"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}